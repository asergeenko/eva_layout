import streamlit as st
import pandas as pd
import os
from datetime import datetime
from io import BytesIO
import zipfile
import logging


from layout_optimizer import (
    parse_dxf_complete,
    bin_packing_with_inventory,
    plot_layout,
    plot_input_polygons,
    save_dxf_layout_complete,
    Carpet,
)

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
MAX_SHEETS_PER_ORDER = (
    5  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–∏—Å—Ç–æ–≤ –Ω–∞ –æ–¥–∏–Ω –∑–∞–∫–∞–∑ (–Ω–æ–º–µ—Ä –∑–∞–∫–∞–∑–∞ –∏–∑ –∫–æ–ª–æ–Ω–∫–∏ O)
)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler("eva_layout_debug.log", mode="w", encoding="utf-8"),
        logging.StreamHandler(),  # –¢–∞–∫–∂–µ –≤—ã–≤–æ–¥–∏—Ç—å –≤ –∫–æ–Ω—Å–æ–ª—å
    ],
)
logger = logging.getLogger(__name__)

logger.info("=== –ù–ê–ß–ê–õ–û –°–ï–°–°–ò–ò EVA LAYOUT ===")
logger.info(f"MAX_SHEETS_PER_ORDER = {MAX_SHEETS_PER_ORDER}")

# Configuration
DEFAULT_SHEET_TYPES = [
    (140, 200),
    (142, 200),
    (144, 200),
    (146, 200),
    (148, 200),
    (140, 195),
    (142, 195),
    (144, 195),
    (146, 195),
    (148, 195),
    (100, 100),
    (150, 150),
    (200, 300),
]
OUTPUT_FOLDER = "output_layouts"
os.makedirs(OUTPUT_FOLDER, exist_ok=True)


# Streamlit App
# Display logo at the very top
try:
    st.image("logo.png", use_container_width=True)
except FileNotFoundError:
    pass  # Skip logo if file not found

# Sheet Inventory Section
st.header("üìã –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ª–∏—Å—Ç–æ–≤")
st.write("–£–∫–∞–∂–∏—Ç–µ –∫–∞–∫–∏–µ –ª–∏—Å—Ç—ã —É –≤–∞—Å –µ—Å—Ç—å –≤ –Ω–∞–ª–∏—á–∏–∏ –∏ –∏—Ö –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ.")

# Initialize session state for sheets
if "available_sheets" not in st.session_state:
    st.session_state.available_sheets = []

# Update existing sheets to have color if missing (for backward compatibility)
for sheet in st.session_state.available_sheets:
    if "color" not in sheet:
        sheet["color"] = "—Å–µ—Ä—ã–π"  # Default color for existing sheets

# Add new sheet type
st.subheader("–î–æ–±–∞–≤–∏—Ç—å —Ç–∏–ø –ª–∏—Å—Ç–∞")
col1, col2, col3 = st.columns([2, 2, 1])

with col1:
    sheet_type_option = st.selectbox(
        "–í—ã–±–µ—Ä–∏—Ç–µ —Ä–∞–∑–º–µ—Ä –ª–∏—Å—Ç–∞ (—Å–º)",
        ["–ü—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–π"] + [f"{w}x{h}" for w, h in DEFAULT_SHEET_TYPES],
        key="sheet_type_select",
    )

    if sheet_type_option == "–ü—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–π":
        sheet_width = st.number_input(
            "–®–∏—Ä–∏–Ω–∞ (—Å–º)",
            min_value=50,
            max_value=1000,
            step=1,
            value=140,
            key="custom_width",
        )
        sheet_height = st.number_input(
            "–í—ã—Å–æ—Ç–∞ (—Å–º)",
            min_value=50,
            max_value=1000,
            step=1,
            value=200,
            key="custom_height",
        )
        selected_size = (sheet_width, sheet_height)
    else:
        selected_size = tuple(map(int, sheet_type_option.split("x")))

    # Color selection
    sheet_color = st.selectbox("–¶–≤–µ—Ç –ª–∏—Å—Ç–∞", ["—á—ë—Ä–Ω—ã–π", "—Å–µ—Ä—ã–π"], key="sheet_color")

with col2:
    sheet_count = st.number_input(
        "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–∏—Å—Ç–æ–≤", min_value=1, max_value=100, value=5, key="sheet_count"
    )
    sheet_name = st.text_input(
        "–ù–∞–∑–≤–∞–Ω–∏–µ —Ç–∏–ø–∞ –ª–∏—Å—Ç–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)",
        value=f"–õ–∏—Å—Ç {selected_size[0]}x{selected_size[1]} {sheet_color}",
        key="sheet_name",
    )

with col3:
    st.write("")
    st.write("")
    if st.button("‚ûï –î–æ–±–∞–≤–∏—Ç—å", key="add_sheet"):
        new_sheet = {
            "name": sheet_name,
            "width": selected_size[0],
            "height": selected_size[1],
            "color": sheet_color,
            "count": sheet_count,
            "used": 0,
        }
        st.session_state.available_sheets.append(new_sheet)
        st.success(
            f"–î–æ–±–∞–≤–ª–µ–Ω —Ç–∏–ø –ª–∏—Å—Ç–∞: {new_sheet['name']} ({new_sheet['count']} —à—Ç.)"
        )
        st.rerun()

# Display current sheet inventory
if st.session_state.available_sheets:
    st.subheader("üìä –î–æ—Å—Ç—É–ø–Ω—ã–µ –ª–∏—Å—Ç—ã")

    # Create DataFrame for display
    sheets_data = []
    total_sheets = 0
    for i, sheet in enumerate(st.session_state.available_sheets):
        # Add color indicator
        color = sheet.get("color", "–Ω–µ —É–∫–∞–∑–∞–Ω")
        color_emoji = "‚ö´" if color == "—á—ë—Ä–Ω—ã–π" else "‚ö™" if color == "—Å–µ—Ä—ã–π" else "üîò"
        color_display = f"{color_emoji}"

        sheets_data.append(
            {
                "‚Ññ": i + 1,
                "–ù–∞–∑–≤–∞–Ω–∏–µ": sheet["name"],
                "–†–∞–∑–º–µ—Ä (—Å–º)": f"{sheet['width']}x{sheet['height']}",
                "–¶–≤–µ—Ç": color_display,
                "–î–æ—Å—Ç—É–ø–Ω–æ": f"{sheet['count'] - sheet['used']}/{sheet['count']}",
                "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ": sheet["used"],
            }
        )
        total_sheets += sheet["count"]

    sheets_df = pd.DataFrame(sheets_data)
    st.dataframe(sheets_df, use_container_width=True)

    col1, col2 = st.columns([3, 1])
    with col1:
        st.metric("–í—Å–µ–≥–æ –ª–∏—Å—Ç–æ–≤ –≤ –Ω–∞–ª–∏—á–∏–∏", total_sheets)
    with col2:
        if st.button("üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å –≤—Å–µ", key="clear_sheets"):
            st.session_state.available_sheets = []
            st.rerun()
else:
    st.info("–î–æ–±–∞–≤—å—Ç–µ —Ç–∏–ø—ã –ª–∏—Å—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ —É –≤–∞—Å –µ—Å—Ç—å –≤ –Ω–∞–ª–∏—á–∏–∏.")

# Order Loading Section
st.header("üìã –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–∫–∞–∑–æ–≤ –∏–∑ Excel —Ç–∞–±–ª–∏—Ü—ã")

# Initialize session state for orders
if "selected_orders" not in st.session_state:
    st.session_state.selected_orders = []
if "manual_files" not in st.session_state:
    st.session_state.manual_files = []

# Excel file upload
excel_file = st.file_uploader(
    "–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –∑–∞–∫–∞–∑–æ–≤ Excel", type=["xlsx", "xls"], key="excel_upload"
)


@st.cache_data(ttl=600)  # Cache for 10 minutes
def load_excel_file(file_content):
    """Load and cache Excel file processing - optimized for speed"""
    # Only load the ZAKAZ sheet instead of all sheets for faster loading
    try:
        excel_data = pd.read_excel(
            BytesIO(file_content),
            sheet_name="ZAKAZ",  # Load only ZAKAZ sheet
            header=None,
            date_format=None,
            parse_dates=False,
            engine="openpyxl",  # Use faster engine
        )
        return {"ZAKAZ": excel_data}
    except ValueError:
        # If ZAKAZ sheet doesn't exist, load all sheets to show available ones
        excel_data = pd.read_excel(
            BytesIO(file_content),
            sheet_name=None,
            header=None,
            date_format=None,
            parse_dates=False,
            engine="openpyxl",
        )
        return excel_data


if excel_file is not None:
    try:
        with st.spinner("–ó–∞–≥—Ä—É–∑–∫–∞ Excel —Ñ–∞–π–ª–∞..."):
            # Read Excel file with caching - use file hash for cache key
            file_content = excel_file.read()
            file_hash = hash(file_content)
            excel_data = load_excel_file(file_content)
            logger.info(f"Excel —Ñ–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω. –õ–∏—Å—Ç—ã: {list(excel_data.keys())}")

        # Process only the "ZAKAZ" sheet
        all_orders = []
        target_sheet = "ZAKAZ"

        if target_sheet in excel_data:
            sheet_name = target_sheet
            df = excel_data[sheet_name]

            # Skip first 2 rows (headers), start from row 2 (index 2)
            if df.shape[0] > 2:
                data_rows = df.iloc[2:].copy()

                # Check for empty "–°–¥–µ–ª–∞–Ω–æ" column (index 2)
                if df.shape[1] > 3:  # Make sure we have enough columns
                    pending_orders = data_rows[
                        data_rows.iloc[:, 2].isna() | (data_rows.iloc[:, 2] == "")
                    ]

                    for idx, row in pending_orders.iterrows():
                        if pd.notna(
                            row.iloc[3]
                        ):  # Check if –ê—Ä—Ç–∏–∫—É–ª (column D) is not empty
                            # Get color from column I (index 8)
                            color = (
                                str(row.iloc[8]).lower().strip()
                                if pd.notna(row.iloc[8]) and df.shape[1] > 8
                                else ""
                            )
                            # Normalize color values
                            if "—á–µ—Ä–Ω" in color or "black" in color:
                                color = "—á—ë—Ä–Ω—ã–π"
                            elif "—Å–µ—Ä" in color or "gray" in color or "grey" in color:
                                color = "—Å–µ—Ä—ã–π"
                            else:
                                color = "—Å–µ—Ä—ã–π"  # Default color if not specified

                            # Create unique order_id for each row (Excel row number + sheet name)
                            unique_order_id = f"{sheet_name}_row_{idx}"

                            order = {
                                "sheet": sheet_name,
                                "row_index": idx,
                                "date": str(row.iloc[0])
                                if pd.notna(row.iloc[0])
                                else "",
                                "article": str(row.iloc[3]),
                                "product": str(row.iloc[4])
                                if pd.notna(row.iloc[4])
                                else "",
                                "client": str(row.iloc[5])
                                if pd.notna(row.iloc[5])
                                else ""
                                if df.shape[1] > 5
                                else "",
                                "order_id": unique_order_id,  # Use unique ID for each Excel row
                                "color": color,
                                "product_type": str(row.iloc[7])
                                if pd.notna(row.iloc[7]) and df.shape[1] > 7
                                else "",
                                "border_color": row.iloc[10],
                            }
                            all_orders.append(order)
        else:
            st.warning(
                f"‚ö†Ô∏è –õ–∏—Å—Ç '{target_sheet}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ Excel —Ñ–∞–π–ª–µ. –î–æ—Å—Ç—É–ø–Ω—ã–µ –ª–∏—Å—Ç—ã: {list(excel_data.keys())}"
            )

        if all_orders:
            st.success(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(all_orders)} –Ω–µ–≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö –∑–∞–∫–∞–∑–æ–≤")
            logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(all_orders)} –Ω–µ–≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö –∑–∞–∫–∞–∑–æ–≤ –≤ Excel")

            # Display orders for selection
            st.subheader("üìù –í—ã–±–µ—Ä–∏—Ç–µ –∑–∞–∫–∞–∑—ã –¥–ª—è —Ä–∞—Å–∫—Ä–æ—è")

            # Add search/filter options
            col_filter1, col_filter2 = st.columns([1, 1])
            with col_filter1:
                search_article = st.text_input(
                    "üîç –ü–æ–∏—Å–∫ –ø–æ –∞—Ä—Ç–∏–∫—É–ª—É:",
                    placeholder="–í–≤–µ–¥–∏—Ç–µ —á–∞—Å—Ç—å –∞—Ä—Ç–∏–∫—É–ª–∞",
                    key="search_article",
                )
            with col_filter2:
                search_product = st.text_input(
                    "üîç –ü–æ–∏—Å–∫ –ø–æ —Ç–æ–≤–∞—Ä—É:",
                    placeholder="–í–≤–µ–¥–∏—Ç–µ —á–∞—Å—Ç—å –Ω–∞–∑–≤–∞–Ω–∏—è",
                    key="search_product",
                )

            # Filter orders based on search
            filtered_orders = all_orders
            if search_article:
                filtered_orders = [
                    order
                    for order in filtered_orders
                    if search_article.lower() in order["article"].lower()
                ]
            if search_product:
                filtered_orders = [
                    order
                    for order in filtered_orders
                    if search_product.lower() in order["product"].lower()
                ]

            if filtered_orders != all_orders:
                st.info(
                    f"üîç –ù–∞–π–¥–µ–Ω–æ {len(filtered_orders)} –∑–∞–∫–∞–∑–æ–≤ –∏–∑ {len(all_orders)} (–ø—Ä–∏–º–µ–Ω–µ–Ω—ã —Ñ–∏–ª—å—Ç—Ä—ã)"
                )

            # Update all_orders with filtered results for display
            display_orders = filtered_orders

            # Create selection interface with all orders (no pagination)
            orders_to_show = display_orders
            start_idx = 0

            # Display orders with interactive controls
            if orders_to_show:
                # Interactive table with controls for each row
                st.markdown("**–í—ã–±–µ—Ä–∏—Ç–µ –∑–∞–∫–∞–∑—ã –¥–ª—è —Ä–∞—Å–∫—Ä–æ—è:**")

                # Prepare data for DataFrame display
                orders_data = []
                for i, order in enumerate(orders_to_show):
                    actual_idx = start_idx + i

                    # Get current selection state and quantity
                    is_selected = st.session_state.get(f"order_{actual_idx}", False)
                    current_qty = st.session_state.get(f"quantity_{actual_idx}", 1)

                    # Color emoji
                    color = order.get("color", "—Å–µ—Ä—ã–π")
                    color_emoji = (
                        "‚ö´"
                        if color == "—á—ë—Ä–Ω—ã–π"
                        else "‚ö™"
                        if color == "—Å–µ—Ä—ã–π"
                        else "üîò"
                    )

                    orders_data.append(
                        {
                            "‚Ññ": actual_idx + 1,
                            "–í—ã–±—Ä–∞—Ç—å": "‚úì" if is_selected else "",
                            "–ö–æ–ª-–≤–æ": current_qty,
                            "–ê—Ä—Ç–∏–∫—É–ª": order["article"],
                            "–¢–æ–≤–∞—Ä": order["product"][:40] + "..."
                            if len(order["product"]) > 40
                            else order["product"],
                            "–¢–∏–ø": order.get("product_type", ""),
                            "–¶–≤–µ—Ç": color_emoji,
                            "–î–∞—Ç–∞": order.get("date", "")[:10]
                            if order.get("date", "")
                            else "",
                            "–ö–∞–Ω—Ç —Ü–≤–µ—Ç": order.get("border_color", ""),
                        }
                    )

                # Create columns for interactive controls
                for i, order in enumerate(orders_to_show):
                    actual_idx = start_idx + i

                    cols = st.columns([1, 2, 10, 6, 3, 3])

                    # Selection checkbox
                    with cols[0]:
                        is_selected = st.checkbox(
                            f"‚Ññ{actual_idx + 1}",
                            value=st.session_state.get(f"order_{actual_idx}", False),
                            key=f"select_{actual_idx}",
                            label_visibility="collapsed",
                        )
                        st.session_state[f"order_{actual_idx}"] = is_selected

                    # Quantity number input
                    with cols[1]:
                        quantity = st.number_input(
                            f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–ª—è –∑–∞–∫–∞–∑–∞ {actual_idx + 1}",
                            min_value=1,
                            max_value=100,
                            value=st.session_state.get(f"quantity_{actual_idx}", 1),
                            key=f"qty_{actual_idx}",
                            label_visibility="collapsed",
                        )
                        st.session_state[f"quantity_{actual_idx}"] = quantity

                    # Display order info for reference
                    with cols[2]:
                        st.write(f"**{order['article']}**")

                    with cols[3]:
                        product_text = (
                            order["product"][:30] + "..."
                            if len(order["product"]) > 30
                            else order["product"]
                        )
                        st.write(product_text)

                    with cols[4]:
                        color = order.get("color", "—Å–µ—Ä—ã–π")
                        color_emoji = (
                            "‚ö´"
                            if color == "—á—ë—Ä–Ω—ã–π"
                            else "‚ö™"
                            if color == "—Å–µ—Ä—ã–π"
                            else "üîò"
                        )
                        st.write(f"{color_emoji} {order.get('product_type', '')}")

                    with cols[5]:
                        st.write(order.get("border_color", ""))

                # Bulk controls
                col1, col2 = st.columns([1, 1])
                with col1:
                    if st.button("‚úÖ –í—ã–±—Ä–∞—Ç—å –≤—Å–µ", key="select_all_orders"):
                        for i in range(len(orders_to_show)):
                            st.session_state[f"order_{start_idx + i}"] = True
                        st.rerun()

                with col2:
                    if st.button("‚ùå –°–Ω—è—Ç—å –≤—ã–±–æ—Ä", key="deselect_all_orders"):
                        for i in range(len(orders_to_show)):
                            st.session_state[f"order_{start_idx + i}"] = False
                        st.rerun()

            # Collect all selected orders, multiplying by quantity
            all_selected_orders = []
            for i in range(len(display_orders)):
                if st.session_state.get(f"order_{i}", False):
                    order = display_orders[i]
                    quantity = st.session_state.get(f"quantity_{i}", 1)

                    # Add the order multiple times based on quantity
                    for repeat_num in range(quantity):
                        # Create a copy of the order with a unique identifier
                        repeated_order = order.copy()
                        repeated_order["repeat_index"] = repeat_num + 1
                        repeated_order["original_index"] = i

                        # Make order_id unique for each repeat
                        if quantity > 1:
                            repeated_order["order_id"] = (
                                f"{order['order_id']}_–ø–æ–≤—Ç–æ—Ä_{repeat_num + 1}"
                            )

                        all_selected_orders.append(repeated_order)

            if all_selected_orders:
                # Count unique orders
                unique_orders = len(
                    set(
                        order.get("original_index", i)
                        for i, order in enumerate(all_selected_orders)
                    )
                )
                total_orders = len(all_selected_orders)

                st.info(f"üìã –í—ã–±—Ä–∞–Ω–æ {len(all_selected_orders)} –∑–∞–∫–∞–∑–æ–≤")

                # Store selected orders in session state
                st.session_state.selected_orders = all_selected_orders
                logger.info(f"–í—ã–±—Ä–∞–Ω–æ {len(all_selected_orders)} –∑–∞–∫–∞–∑–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
                # Log only first few orders to avoid slowdown
                if len(all_selected_orders) <= 5:
                    for order in all_selected_orders:
                        logger.info(
                            f"  –ó–∞–∫–∞–∑ {order.get('order_id', 'N/A')}: {order.get('article', 'N/A')}"
                        )
                else:
                    # Log only first 3 and last 2 for large lists
                    for order in all_selected_orders[:3]:
                        logger.info(
                            f"  –ó–∞–∫–∞–∑ {order.get('order_id', 'N/A')}: {order.get('article', 'N/A')}"
                        )
                    logger.info(
                        f"  ... (–ø—Ä–æ–ø—É—â–µ–Ω–æ {len(all_selected_orders) - 5} –∑–∞–∫–∞–∑–æ–≤) ..."
                    )
                    for order in all_selected_orders[-2:]:
                        logger.info(
                            f"  –ó–∞–∫–∞–∑ {order.get('order_id', 'N/A')}: {order.get('article', 'N/A')}"
                        )
        else:
            st.warning("‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–µ–≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö –∑–∞–∫–∞–∑–æ–≤ –≤ —É–∫–∞–∑–∞–Ω–Ω—ã—Ö –º–µ—Å—è—Ü–∞—Ö")

    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ Excel —Ñ–∞–π–ª–∞: {e}")
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ Excel: {e}")
        import traceback

        logger.error(f"–ü–æ–ª–Ω–∞—è —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞ –æ—à–∏–±–∫–∏: {traceback.format_exc()}")
        st.error("üí° **–í–æ–∑–º–æ–∂–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è:**")
        st.error("‚Ä¢ –°–æ—Ö—Ä–∞–Ω–∏—Ç–µ Excel —Ñ–∞–π–ª –≤ –Ω–æ–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ (.xlsx)")
        st.error("‚Ä¢ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –¥–∞—Ç –≤ —Ñ–∞–π–ª–µ")
        st.error(
            "‚Ä¢ –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤ –¥–∞—Ç–∞—Ö –Ω–µ—Ç –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, 30 —Ñ–µ–≤—Ä–∞–ª—è)"
        )

# Initialize auto_loaded_files
auto_loaded_files = []

# DXF files will be loaded on demand during optimization
# This section shows what will be processed when optimization starts
if st.session_state.selected_orders:
    # st.subheader("üìã –ì–æ—Ç–æ–≤—ã–µ –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–∫–∞–∑—ã")

    # st.success(f"‚úÖ –í—ã–±—Ä–∞–Ω–æ {len(st.session_state.selected_orders)} –∑–∞–∫–∞–∑–æ–≤")
    # st.info("üí° DXF —Ñ–∞–π–ª—ã –±—É–¥—É—Ç –∑–∞–≥—Ä—É–∂–µ–Ω—ã –ø—Ä–∏ –Ω–∞–∂–∞—Ç–∏–∏ –∫–Ω–æ–ø–∫–∏ '–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–∞—Å–∫—Ä–æ–π' –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞.")

    # Show preview of what will be loaded
    articles_found = []
    articles_not_found = []

    # Create a file-like object with name attribute
    class FileObj:
        def __init__(self, content, name):
            self.content = BytesIO(content)
            self.name = name

        def read(self):
            return self.content.read()

        def seek(self, pos):
            return self.content.seek(pos)

    def get_dxf_files_for_product_type(article, product_name, product_type):
        """Get DXF files for a specific product type based on the mapping rules."""

        found_files = []

        logger.info(
            f"–ü–æ–∏—Å–∫ DXF —Ñ–∞–π–ª–æ–≤: –∞—Ä—Ç–∏–∫—É–ª='{article}', —Ç–æ–≤–∞—Ä='{product_name}', —Ç–∏–ø='{product_type}'"
        )

        # Find the base folder for this article/product
        base_folder = find_product_folder(article, product_name)

        if base_folder and os.path.exists(base_folder):
            logger.info(f"–ù–∞–π–¥–µ–Ω–∞ –±–∞–∑–æ–≤–∞—è –ø–∞–ø–∫–∞: {base_folder}")

            # Look for DXF folder first, then try the base folder directly
            dxf_folder = os.path.join(base_folder, "DXF")
            if os.path.exists(dxf_folder):
                search_folder = dxf_folder
                logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–æ–¥–ø–∞–ø–∫–∞ DXF: {search_folder}")
            else:
                search_folder = base_folder
                logger.info(f"DXF —Ñ–∞–π–ª—ã –∏—â—É—Ç—Å—è –Ω–µ–ø–æ—Å—Ä–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ –≤: {search_folder}")

            # Get all DXF files in the folder
            all_dxf_files = []
            try:
                for file in os.listdir(search_folder):
                    if file.lower().endswith(".dxf"):
                        all_dxf_files.append(os.path.join(search_folder, file))
            except OSError as e:
                logger.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –ø–∞–ø–∫–∏ {search_folder}: {e}")
                return []

            # Apply product type specific filtering
            if product_type == "–±–æ—Ä—Ç":
                # Files 1.dxf to 9.dxf
                for i in range(1, 10):
                    target_file = os.path.join(search_folder, f"{i}.dxf")
                    if os.path.exists(target_file):
                        found_files.append(target_file)

            elif product_type == "–≤–æ–¥–∏—Ç–µ–ª—å":
                # Only 1.dxf
                target_file = os.path.join(search_folder, "1.dxf")
                if os.path.exists(target_file):
                    found_files.append(target_file)

            elif product_type == "–ø–µ—Ä–µ–¥–Ω–∏–µ":
                # 1.dxf and 2.dxf
                for i in [1, 2]:
                    target_file = os.path.join(search_folder, f"{i}.dxf")
                    if os.path.exists(target_file):
                        found_files.append(target_file)

            elif product_type == "–±–∞–≥–∞–∂–Ω–∏–∫":
                # Files 10.dxf to 16.dxf
                for i in range(10, 17):
                    target_file = os.path.join(search_folder, f"{i}.dxf")
                    if os.path.exists(target_file):
                        found_files.append(target_file)

            elif product_type in ["—Å–∞–º–æ–∫–∞—Ç", "–ª–æ–¥–∫–∞", "–∫–æ–≤–µ—Ä"]:
                # All available files in the folder
                found_files = all_dxf_files

            else:
                # Unknown product type - take all files as fallback
                logger.warning(
                    f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –∏–∑–¥–µ–ª–∏—è: {product_type}, –±–µ—Ä–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã"
                )
                found_files = all_dxf_files

        logger.info(
            f"–†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–∏—Å–∫–∞ –¥–ª—è —Ç–∏–ø–∞ '{product_type}': –Ω–∞–π–¥–µ–Ω–æ {len(found_files)} —Ñ–∞–π–ª–æ–≤"
        )
        if found_files:
            logger.debug(
                f"–ù–∞–π–¥–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã: {[os.path.basename(f) for f in found_files]}"
            )

        return found_files

    def find_product_folder(article, product_name):
        """Find the base folder for a product based on article and product name."""

        logger.info(f"–ü–æ–∏—Å–∫ –ø–∞–ø–∫–∏ –¥–ª—è –∞—Ä—Ç–∏–∫—É–ª–∞: '{article}', —Ç–æ–≤–∞—Ä–∞: '{product_name}'")

        # Strategy 1: Direct search in flat dxf_samples folder structure
        if product_name:
            product_upper = product_name.upper()

            # Search directly in dxf_samples folder for matching folder names
            best_match = None
            best_score = 0

            for item in os.listdir("dxf_samples"):
                item_path = os.path.join("dxf_samples", item)
                if os.path.isdir(item_path):
                    score = calculate_folder_match_score(product_name, item)
                    if score > best_score:
                        best_score = score
                        best_match = item_path

            if best_match and best_score >= 6:
                logger.info(
                    f"–ù–∞–π–¥–µ–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø–æ –∏–º–µ–Ω–∏ —Ç–æ–≤–∞—Ä–∞: {best_match} (—Å—á—ë—Ç: {best_score})"
                )
                return best_match

            # Special categories handling
            special_keywords = {
                "–ª–æ–¥–∫–∞": ["–õ–æ–¥–∫–∞", "ADMIRAL", "ABAKAN", "AKVA", "–ê–ì–£–õ", "–ê–∑–∏–º—É—Ç"],
                "–∫–æ–≤–µ—Ä": ["–ö–æ–≤—Ä–∏–∫"],
                "—Å–∞–º–æ–∫–∞—Ç": ["–î–ï–ö–ê", "KUGOO"],
            }

            for category, keywords in special_keywords.items():
                for keyword in keywords:
                    if keyword.upper() in product_upper:
                        # Search for folders containing this keyword
                        for item in os.listdir("dxf_samples"):
                            if keyword.lower() in item.lower():
                                folder_path = os.path.join("dxf_samples", item)
                                if os.path.isdir(folder_path):
                                    logger.info(
                                        f"–ù–∞–π–¥–µ–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø–æ –∫–ª—é—á–µ–≤–æ–º—É —Å–ª–æ–≤—É '{keyword}': {folder_path}"
                                    )
                                    return folder_path

        # Strategy 2: Parse article format like EVA_BORT+Brand+Model
        if "+" in article:
            parts = article.split("+")
            if len(parts) >= 3:
                brand = parts[1].strip()
                model_info = parts[2].strip()

                logger.info(f"–ü–∞—Ä—Å–∏–Ω–≥ –∞—Ä—Ç–∏–∫—É–ª–∞: –±—Ä–µ–Ω–¥='{brand}', –º–æ–¥–µ–ª—å='{model_info}'")

                # Handle special case mappings first
                special_mappings = {
                    "Kugoo": ["–î–ï–ö–ê KUGOO KIRIN M4 PRO", "–î–ï–ö–ê KUGOO M4 PRO JILONG"],
                    "–ê–±–∞–∫–∞–Ω": ["–õ–æ–¥–∫–∞ ABAKAN 430 JET"],
                    "Admiral": [
                        "–õ–æ–¥–∫–∞ ADMIRAL 335",
                        "–õ–æ–¥–∫–∞ ADMIRAL 340",
                        "–õ–æ–¥–∫–∞ ADMIRAL 410",
                    ],
                    "AKVA": ["–õ–æ–¥–∫–∞ AKVA 2600", "–õ–æ–¥–∫–∞ AKVA 2800"],
                }

                if brand in special_mappings:
                    for folder_name in special_mappings[brand]:
                        folder_path = os.path.join("dxf_samples", folder_name)
                        if os.path.exists(folder_path):
                            logger.info(
                                f"–ù–∞–π–¥–µ–Ω–æ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ: {folder_path}"
                            )
                            return folder_path

                # For standard automotive brands, search the flat folder structure
                # Create search term from brand and model
                search_term = f"{brand} {model_info}".upper()

                # Find best match in flat folder structure
                best_match = None
                best_score = 0

                for item in os.listdir("dxf_samples"):
                    item_path = os.path.join("dxf_samples", item)
                    if os.path.isdir(item_path):
                        score = calculate_folder_match_score(search_term, item)
                        if score > best_score:
                            best_score = score
                            best_match = item_path

                if best_match and best_score >= 3:
                    logger.info(
                        f"–ù–∞–π–¥–µ–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø–æ –∞—Ä—Ç–∏–∫—É–ª—É: {best_match} (—Å—á—ë—Ç: {best_score})"
                    )
                    return best_match

        # Strategy 3: Direct path mapping
        direct_path = f"dxf_samples/{article}"
        if os.path.exists(direct_path):
            return direct_path

        return None

    def calculate_folder_match_score(search_term, folder_name):
        """Calculate how well a folder name matches the search term."""
        import re

        search_lower = search_term.lower()
        folder_lower = folder_name.lower()
        score = 0

        # Direct substring match
        if search_lower in folder_lower or folder_lower in search_lower:
            score += max(len(search_lower), len(folder_lower)) * 2

        # Word-based matching
        search_words = re.split(r"[\s\-_()]+", search_lower)
        folder_words = re.split(r"[\s\-_()]+", folder_lower)

        # Remove empty words
        search_words = [w for w in search_words if len(w) > 1]
        folder_words = [w for w in folder_words if len(w) > 1]

        for search_word in search_words:
            for folder_word in folder_words:
                if search_word == folder_word:
                    score += len(search_word) * 3
                elif search_word in folder_word:
                    score += len(search_word) * 2
                elif folder_word in search_word:
                    score += len(folder_word) * 2
                elif search_word[:3] == folder_word[:3] and len(search_word) > 2:
                    score += 2  # Partial match for similar words

        logger.debug(f"–°—á—ë—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è '{search_term}' <-> '{folder_name}': {score}")

        return score

    @st.cache_data(ttl=300)  # Cache for 5 minutes
    def find_dxf_files_for_article(article, product_name="", product_type=""):
        """Find DXF files for a given article using the new product type mapping."""
        if product_type:
            return get_dxf_files_for_product_type(article, product_name, product_type)
        else:
            # Fallback to old behavior if product_type not provided
            base_folder = find_product_folder(article, product_name)
            if base_folder:
                found_files = []
                dxf_folder = os.path.join(base_folder, "DXF")
                search_folder = (
                    dxf_folder if os.path.exists(dxf_folder) else base_folder
                )

                try:
                    for file in os.listdir(search_folder):
                        if file.lower().endswith(".dxf"):
                            found_files.append(os.path.join(search_folder, file))
                except OSError:
                    pass

                return found_files
            return []


# Additional DXF files section (always available)
st.subheader("üìé –ó–∞–≥—Ä—É–∑–∏—Ç—å –≤—Ä—É—á–Ω—É—é")
st.write(
    "–î–æ–±–∞–≤—å—Ç–µ DXF —Ñ–∞–π–ª—ã –≥—Ä—É–ø–ø–∞–º–∏. –ö–∞–∂–¥–∞—è –≥—Ä—É–ø–ø–∞ –±—É–¥–µ—Ç –∏–º–µ—Ç—å —Å–≤–æ–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Ü–≤–µ—Ç–∞ –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞."
)

# Initialize session state for file groups
if "file_groups" not in st.session_state:
    st.session_state.file_groups = []
if "group_counter" not in st.session_state:
    st.session_state.group_counter = 1

# File uploader for new files - each selection creates a new group
# Use group_counter in key to reset uploader after each group creation
uploader_key = f"manual_dxf_{len(st.session_state.file_groups)}"
manual_files = st.file_uploader(
    "–í—ã–±–µ—Ä–∏—Ç–µ DXF —Ñ–∞–π–ª—ã (–±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω–∞ –Ω–æ–≤–∞—è –≥—Ä—É–ø–ø–∞)",
    type=["dxf"],
    accept_multiple_files=True,
    key=uploader_key,
)

# Process newly uploaded files - show settings and create group when ready
if manual_files:
    # Store current files for this group configuration
    current_group_key = f"current_group_{len(st.session_state.file_groups)}"

    st.write(f"**–ù–æ–≤–∞—è –≥—Ä—É–ø–ø–∞ #{st.session_state.group_counter}:**")

    # Settings for this group
    col1, col2, col3 = st.columns([1, 1, 1])

    with col1:
        group_color = st.selectbox(
            "–¶–≤–µ—Ç –ª–∏—Å—Ç–∞:",
            options=["—á—ë—Ä–Ω—ã–π", "—Å–µ—Ä—ã–π"],
            index=0,
            key=f"color_{current_group_key}",
            help="–¶–≤–µ—Ç –ª–∏—Å—Ç–∞ –¥–ª—è –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –≥—Ä—É–ø–ø—ã",
        )

    with col2:
        group_quantity = st.number_input(
            "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–ø–∏–π:",
            min_value=1,
            max_value=50,
            value=1,
            key=f"qty_{current_group_key}",
            help="–ö–æ–ø–∏–π –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞",
        )

    with col3:
        group_priority = st.selectbox(
            "–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:",
            options=[1, 2],
            index=1,  # Default to priority 2
            key=f"priority_{current_group_key}",
            help="1 - —Ä–∞–∑–º–µ—â–∞–µ—Ç—Å—è –Ω–∞—Ä–∞–≤–Ω–µ —Å Excel —Ñ–∞–π–ª–∞–º–∏, 2 - –∑–∞–ø–æ–ª–Ω—è–µ—Ç –ø—É—Å—Ç–æ—Ç—ã –Ω–∞ –ª–∏—Å—Ç–∞—Ö",
        )

    # Button to create group with current settings
    if st.button(
        f"‚ûï –°–æ–∑–¥–∞—Ç—å –≥—Ä—É–ø–ø—É #{st.session_state.group_counter}",
        key=f"create_group_{current_group_key}",
    ):
        # Create group with selected settings
        group_files = []
        group_name = f"–ì—Ä—É–ø–ø–∞ #{st.session_state.group_counter}"

        for file in manual_files:
            # Store file content to avoid issues with file handles
            file.seek(0)
            file_content = file.read()

            for copy_num in range(group_quantity):
                import io

                file_copy = io.BytesIO(file_content)
                file_copy.name = file.name
                file_copy.color = group_color
                file_copy.priority = group_priority
                file_copy.order_id = f"group_{st.session_state.group_counter}"
                file_copy.copy_number = copy_num + 1
                file_copy.original_name = file.name
                file_copy.group_id = st.session_state.group_counter

                # Create unique name for multiple copies
                if group_quantity > 1:
                    base_name = file.name.replace(".dxf", "")
                    file_copy.display_name = f"{base_name}_–∫–æ–ø–∏—è_{copy_num + 1}.dxf"
                else:
                    file_copy.display_name = file.name

                file_copy.copy_info = f"copy_{copy_num + 1}_of_{group_quantity}"
                group_files.append(file_copy)

        # Add group to session state
        new_group = {
            "id": st.session_state.group_counter,
            "name": group_name,
            "files": [f.name for f in manual_files],
            "color": group_color,
            "priority": group_priority,
            "quantity": group_quantity,
            "total_objects": len(manual_files) * group_quantity,
            "file_objects": group_files,
        }

        st.session_state.file_groups.append(new_group)
        st.session_state.group_counter += 1

        st.success(
            f"‚úÖ –ì—Ä—É–ø–ø–∞ —Å–æ–∑–¥–∞–Ω–∞: {len(manual_files)} —Ñ–∞–π–ª–æ–≤ √ó {group_quantity} –∫–æ–ø–∏–π = {len(group_files)} –æ–±—ä–µ–∫—Ç–æ–≤ (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç {group_priority})"
        )

        # Force rerun to reset uploader
        st.rerun()

    # Show preview of what will be created
    total_objects = len(manual_files) * group_quantity
    color_emoji = "‚ö´" if group_color == "—á—ë—Ä–Ω—ã–π" else "‚ö™"


# Display existing groups table
if st.session_state.file_groups:
    st.subheader("üìã –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –≥—Ä—É–ø–ø—ã —Ñ–∞–π–ª–æ–≤")

    groups_data = []
    total_objects = 0

    for group in st.session_state.file_groups:
        color_emoji = "‚ö´" if group["color"] == "—á—ë—Ä–Ω—ã–π" else "‚ö™"
        files_list = ", ".join(group["files"][:3])  # Show first 3 files
        if len(group["files"]) > 3:
            files_list += f" –∏ –µ—â—ë {len(group['files']) - 3}..."

        groups_data.append(
            {
                "–ì—Ä—É–ø–ø–∞": group["name"],
                "–§–∞–π–ª—ã": files_list,
                "–¶–≤–µ—Ç": f"{color_emoji} {group['color']}",
                "–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç": group.get("priority", 2),
                "–ö–æ–ø–∏–π –Ω–∞ —Ñ–∞–π–ª": group["quantity"],
            }
        )
        total_objects += group["total_objects"]

    groups_df = pd.DataFrame(groups_data)
    st.dataframe(groups_df, use_container_width=True)

    col1, col2 = st.columns([3, 1])
    with col1:
        st.metric("–í—Å–µ–≥–æ –æ–±—ä–µ–∫—Ç–æ–≤ –≤–æ –≤—Å–µ—Ö –≥—Ä—É–ø–ø–∞—Ö", total_objects)
    with col2:
        if st.button("üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å –≤—Å–µ –≥—Ä—É–ø–ø—ã", key="clear_all_groups"):
            st.session_state.file_groups = []
            st.session_state.group_counter = 1
            st.rerun()

    # Prepare all files for processing (flatten all groups)
    all_manual_files = []
    for group in st.session_state.file_groups:
        all_manual_files.extend(group["file_objects"])

    st.session_state.manual_files = all_manual_files
else:
    st.session_state.manual_files = []


# Legacy compatibility - no longer needed but kept for backward compatibility
if "manual_file_settings" not in st.session_state:
    st.session_state.manual_file_settings = {}

# Show status messages based on what's available
has_manual_files = len(st.session_state.file_groups) > 0
if st.session_state.selected_orders and has_manual_files:
    st.info("üí° –ë—É–¥—É—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã –∑–∞–∫–∞–∑—ã –∏–∑ Excel + –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã")
elif st.session_state.selected_orders:
    st.info("üí° –ë—É–¥—É—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã —Ç–æ–ª—å–∫–æ –∑–∞–∫–∞–∑—ã –∏–∑ Excel —Ç–∞–±–ª–∏—Ü—ã")
elif has_manual_files:
    st.info("üí° –ë—É–¥—É—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã —Ç–æ–ª—å–∫–æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã")
else:
    st.warning(
        "‚ö†Ô∏è –ó–∞–≥—Ä—É–∑–∏—Ç–µ Excel —Ñ–∞–π–ª —Å –∑–∞–∫–∞–∑–∞–º–∏ –∏–ª–∏ –¥–æ–±–∞–≤—å—Ç–µ DXF —Ñ–∞–π–ª—ã –≤—Ä—É—á–Ω—É—é –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è"
    )

if st.button("üöÄ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–∞—Å–∫—Ä–æ–π"):
    logger.info("=== –ù–ê–ß–ê–õ–û –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò –†–ê–°–ö–†–û–Ø ===")
    if not st.session_state.available_sheets:
        logger.error("–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ª–∏—Å—Ç–æ–≤ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏")
        st.error("‚ö†Ô∏è –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –¥–æ–±–∞–≤—å—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω —Ç–∏–ø –ª–∏—Å—Ç–∞ –≤ –Ω–∞–ª–∏—á–∏–∏.")
    elif not st.session_state.selected_orders and not st.session_state.manual_files:
        logger.error("–ù–µ—Ç —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏")
        st.error(
            "‚ö†Ô∏è –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ –∑–∞–∫–∞–∑—ã –∏–∑ Excel —Ç–∞–±–ª–∏—Ü—ã –∏–ª–∏ –¥–æ–±–∞–≤—å—Ç–µ DXF —Ñ–∞–π–ª—ã –≤—Ä—É—á–Ω—É—é."
        )
    else:
        # Now load DXF files on demand
        st.header("üì• –ó–∞–≥—Ä—É–∑–∫–∞ DXF —Ñ–∞–π–ª–æ–≤")

        # Load files from selected orders
        auto_loaded_files = []
        manual_files_with_color = []

        # Create FileObj class for this context
        class FileObj:
            def __init__(self, content, name):
                self.content = BytesIO(content)
                self.name = name

            def read(self):
                return self.content.read()

            def seek(self, pos):
                return self.content.seek(pos)

        # Load files from orders
        progress_bar = st.progress(0)
        status_text = st.empty()

        total_orders = len(st.session_state.selected_orders)
        for i, order in enumerate(st.session_state.selected_orders):
            progress = (i + 1) / total_orders
            progress_bar.progress(progress)
            status_text.text(
                f"–ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª—ã –¥–ª—è –∑–∞–∫–∞–∑–∞ {i + 1}/{total_orders}: {order['product'][:50]}..."
            )

            article = order["article"]
            product = order["product"]
            product_type = order.get("product_type", "")

            logger.info(
                f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∑–∞–∫–∞–∑: –∞—Ä—Ç–∏–∫—É–ª={article}, —Ç–æ–≤–∞—Ä={product}, —Ç–∏–ø={product_type}"
            )

            found_dxf_files = find_dxf_files_for_article(article, product, product_type)

            if found_dxf_files:
                logger.info(
                    f"–ù–∞–π–¥–µ–Ω–æ {len(found_dxf_files)} DXF —Ñ–∞–π–ª–æ–≤ –¥–ª—è —Ç–∏–ø–∞ '{product_type}'"
                )
                for file_path in found_dxf_files:
                    try:
                        with open(file_path, "rb") as f:
                            file_content = f.read()

                        display_name = f"{product}_{os.path.basename(file_path)}"
                        file_obj = FileObj(file_content, display_name)
                        file_obj.color = order.get("color", "—Å–µ—Ä—ã–π")
                        file_obj.order_id = order.get("order_id", "unknown")
                        auto_loaded_files.append(file_obj)
                        logger.debug(
                            f"–ó–∞–≥—Ä—É–∂–µ–Ω —Ñ–∞–π–ª {display_name} –¥–ª—è –∑–∞–∫–∞–∑–∞ {file_obj.order_id}"
                        )
                    except Exception as e:
                        st.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {file_path}: {e}")
            else:
                st.warning(
                    f"‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω—ã DXF —Ñ–∞–π–ª—ã –¥–ª—è –∑–∞–∫–∞–∑–∞: {product} (—Ç–∏–ø: {product_type})"
                )

        # Load manual files if any (already configured with colors and quantities)
        if hasattr(st.session_state, "manual_files") and st.session_state.manual_files:
            for file in st.session_state.manual_files:
                # Files are already configured with color, order_id, and display_name
                manual_files_with_color.append(file)

        # Combine all files
        dxf_files = auto_loaded_files + manual_files_with_color

        progress_bar.empty()
        status_text.text(
            f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(dxf_files)} —Ñ–∞–π–ª–æ–≤ ({len(auto_loaded_files)} –∏–∑ –∑–∞–∫–∞–∑–æ–≤, {len(manual_files_with_color)} –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö)"
        )

        logger.info(
            f"–ù–∞—á–∏–Ω–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é —Å {len(dxf_files)} DXF —Ñ–∞–π–ª–∞–º–∏ –∏ {len(st.session_state.available_sheets)} —Ç–∏–ø–∞–º–∏ –ª–∏—Å—Ç–æ–≤"
        )
        # Parse DXF files
        st.header("üìÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ DXF —Ñ–∞–π–ª–æ–≤")
        carpets = []
        original_dxf_data_map = {}  # Store original DXF data for each file

        # Parse loaded DXF files
        logger.info("–ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ DXF —Ñ–∞–π–ª–æ–≤...")

        # Show progress for file parsing
        progress_bar = st.progress(0)
        status_text = st.empty()

        for idx, file in enumerate(dxf_files):
            # Update progress
            progress = (idx + 1) / len(dxf_files)
            progress_bar.progress(progress)

            # Use display_name if available (for manual files with copies), otherwise use file.name
            display_name = getattr(file, "display_name", file.name)
            status_text.text(f"–ü–∞—Ä—Å–∏–º —Ñ–∞–π–ª {idx + 1}/{len(dxf_files)}: {display_name}")

            file.seek(0)
            file_bytes = BytesIO(file.read())
            parsed_data = parse_dxf_complete(file_bytes, verbose=False)
            if parsed_data and parsed_data["combined_polygon"]:
                # Add color and order information to polygon tuple
                file_color = getattr(file, "color", "—Å–µ—Ä—ã–π")
                file_order_id = getattr(file, "order_id", "unknown")
                file_priority = getattr(
                    file, "priority", 1
                )  # Default priority 1 for Excel files

                # DEBUG: Log all file attributes to understand the issue
                file_attrs = [attr for attr in dir(file) if not attr.startswith("_")]
                logger.debug(f"–§–ê–ô–õ {display_name}: –∞—Ç—Ä–∏–±—É—Ç—ã = {file_attrs}")
                logger.debug(
                    f"–§–ê–ô–õ {display_name}: color = {file_color}, order_id = {file_order_id}, priority = {file_priority}"
                )

                # Use the display_name for polygon identification, include priority
                carpet = Carpet(
                    parsed_data["combined_polygon"],
                    display_name,
                    file_color,
                    file_order_id,
                    file_priority,  # Add priority as 5th element
                )
                carpets.append(carpet)
                logger.info(f"–î–û–ë–ê–í–õ–ï–ù –ü–û–õ–ò–ì–û–ù: order_id={carpet.order_id}")
                # Store original DXF data using display_name as key
                original_dxf_data_map[display_name] = parsed_data
                logger.info(
                    f"–°–û–ó–î–ê–ù –ü–û–õ–ò–ì–û–ù: —Ñ–∞–π–ª={display_name}, –∑–∞–∫–∞–∑={file_order_id}, —Ü–≤–µ—Ç={file_color}"
                )
            else:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø–æ–ª–∏–≥–æ–Ω –∏–∑ —Ñ–∞–π–ª–∞ {display_name}")

        # Clear progress indicators
        progress_bar.empty()
        status_text.text(
            f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(carpets)} –ø–æ–ª–∏–≥–æ–Ω–æ–≤ –∏–∑ {len(dxf_files)} —Ñ–∞–π–ª–æ–≤"
        )

        if not carpets:
            st.error("–í –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö DXF —Ñ–∞–π–ª–∞—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤–∞–ª–∏–¥–Ω—ã—Ö –ø–æ–ª–∏–≥–æ–Ω–æ–≤")
            st.stop()

        # Show order distribution before optimization
        order_counts = {}
        for carpet in carpets:
            order_counts[carpet.order_id] = order_counts.get(carpet.order_id, 0) + 1

        logger.info(f"–ê–Ω–∞–ª–∏–∑ –∑–∞–∫–∞–∑–æ–≤: –Ω–∞–π–¥–µ–Ω–æ {len(order_counts)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–∞–∫–∞–∑–æ–≤")
        for order_id, count in order_counts.items():
            logger.info(f"  ‚Ä¢ –ó–∞–∫–∞–∑ {order_id}: {count} —Ñ–∞–π–ª–æ–≤")

        # Optional input visualization (button-triggered)
        if st.button("üìä –ü–æ–∫–∞–∑–∞—Ç—å –∏—Å—Ö–æ–¥–Ω—ã–µ —Ñ–∞–π–ª—ã", key="show_input_visualization"):
            st.subheader("üîç –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤")
            input_plots = plot_input_polygons(carpets)
            if input_plots:
                # Show color legend
                with st.expander("üé® –¶–≤–µ—Ç–æ–≤–∞—è —Å—Ö–µ–º–∞ —Ñ–∞–π–ª–æ–≤", expanded=False):
                    legend_cols = st.columns(min(5, len(carpets)))
                    for i, carpet in enumerate(carpets):
                        with legend_cols[i % len(legend_cols)]:
                            from layout_optimizer import get_color_for_file

                            color = get_color_for_file(carpet.filename)
                            # Convert RGB to hex for HTML
                            color_hex = f"#{int(color[0]*255):02x}{int(color[1]*255):02x}{int(color[2]*255):02x}"
                            st.markdown(
                                f'<div style="background-color: {color_hex}; padding: 10px; border-radius: 5px; text-align: center; margin: 2px;"><b>{carpet.filename}</b></div>',
                                unsafe_allow_html=True,
                            )

                cols = st.columns(min(3, len(input_plots)))
                for i, (file_name, plot_buf) in enumerate(input_plots.items()):
                    with cols[i % len(cols)]:
                        st.image(
                            plot_buf, caption=f"{file_name}", use_container_width=True
                        )

        # Store original dimensions for comparison later
        original_dimensions = {}

        # Create a summary table with proper unit conversion
        summary_data = []
        total_area_cm2 = 0
        for carpet in carpets:
            poly = carpet.polygon
            bounds = poly.bounds
            width_mm = bounds[2] - bounds[0]
            height_mm = bounds[3] - bounds[1]
            area_mm2 = poly.area

            # Convert from mm to cm
            width_cm = width_mm / 10.0
            height_cm = height_mm / 10.0
            area_cm2 = area_mm2 / 100.0

            # Store original dimensions
            original_dimensions[carpet.filename] = {
                "width_cm": width_cm,
                "height_cm": height_cm,
                "area_cm2": area_cm2,
            }

            total_area_cm2 += area_cm2
            # Add color emoji for display
            color_emoji = (
                "‚ö´" if color == "—á—ë—Ä–Ω—ã–π" else "‚ö™" if color == "—Å–µ—Ä—ã–π" else "üîò"
            )
            color_display = f"{color_emoji} {color}"

            summary_data.append(
                {
                    "–§–∞–π–ª": carpet.filename,
                    "–®–∏—Ä–∏–Ω–∞ (—Å–º)": f"{width_cm:.1f}",
                    "–í—ã—Å–æ—Ç–∞ (—Å–º)": f"{height_cm:.1f}",
                    "–ü–ª–æ—â–∞–¥—å (—Å–º¬≤)": f"{area_cm2:.2f}",
                    "–¶–≤–µ—Ç": color_display,
                }
            )

        # Calculate theoretical minimum using largest available sheet
        largest_sheet_area = max(
            sheet["width"] * sheet["height"]
            for sheet in st.session_state.available_sheets
        )

        # Find largest sheet for scaling reference
        max_sheet_area = 0
        reference_sheet_size = (140, 200)  # default fallback
        for sheet in st.session_state.available_sheets:
            area = sheet["width"] * sheet["height"]
            if area > max_sheet_area:
                max_sheet_area = area
                reference_sheet_size = (sheet["width"], sheet["height"])

        # –ü–æ–ª–∏–≥–æ–Ω—ã –æ—Å—Ç–∞—é—Ç—Å—è –≤ –∏—Å—Ö–æ–¥–Ω–æ–º –º–∞—Å—à—Ç–∞–±–µ (–Ω–µ –º–∞—Å—à—Ç–∞–±–∏—Ä—É—é—Ç—Å—è)
        logger.info(
            f"‚úÖ –ü–æ–ª–∏–≥–æ–Ω—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –∏—Å—Ö–æ–¥–Ω–æ–º –º–∞—Å—à—Ç–∞–±–µ: {len(carpets)} –æ–±—ä–µ–∫—Ç–æ–≤"
        )

        st.header("üîÑ –ü—Ä–æ—Ü–µ—Å—Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏")
        try:
            # Debug processing with detailed info
            # with st.expander("üîç –ü–æ–¥—Ä–æ–±–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏", expanded=False):
            #    debug_layouts, debug_unplaced = bin_packing_with_inventory(polygons, st.session_state.available_sheets, verbose=True, max_sheets_per_order=MAX_SHEETS_PER_ORDER)

            # Actual processing with progress tracking
            st.info("üîÑ –ó–∞–ø—É—Å–∫ –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏...")
            optimization_progress = st.progress(0)
            optimization_status = st.empty()

            # Initialize optimization
            optimization_progress.progress(10)
            optimization_status.text("–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏...")

            logger.info(
                f"–í—ã–∑—ã–≤–∞–µ–º bin_packing_with_inventory —Å MAX_SHEETS_PER_ORDER={MAX_SHEETS_PER_ORDER}"
            )
            logger.info(
                f"–í—Ö–æ–¥–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {len(carpets)} –ø–æ–ª–∏–≥–æ–Ω–æ–≤, {len(st.session_state.available_sheets)} —Ç–∏–ø–æ–≤ –ª–∏—Å—Ç–æ–≤"
            )

            # DEBUG: Log what polygons we're sending
            optimization_progress.progress(20)
            optimization_status.text("–ê–Ω–∞–ª–∏–∑ –≤—Ö–æ–¥–Ω—ã—Ö –ø–æ–ª–∏–≥–æ–Ω–æ–≤...")

            logger.info("–ü–û–õ–ò–ì–û–ù–´ –ü–ï–†–ï–î –û–¢–ü–†–ê–í–ö–û–ô –í bin_packing_with_inventory:")
            for i, carpet in enumerate(carpets):
                logger.info(
                    f"  –ü–æ–ª–∏–≥–æ–Ω {i}: —Ñ–∞–π–ª={carpet.filename}, order_id={carpet.order_id}"
                )

            # Main optimization step
            optimization_progress.progress(50)
            optimization_status.text("–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ —Ä–∞–∑–º–µ—â–µ–Ω–∏—è...")

            # Progress callback function
            def update_progress(percent, status_text):
                optimization_progress.progress(int(percent))
                optimization_status.text(status_text)


            placed_layouts, unplaced_polygons = bin_packing_with_inventory(
                carpets,
                st.session_state.available_sheets,
                verbose=False,
                max_sheets_per_order=MAX_SHEETS_PER_ORDER,
                progress_callback=update_progress,
            )

            # Processing results
            optimization_progress.progress(80)
            optimization_status.text("–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")

            logger.info(
                f"–†–µ–∑—É–ª—å—Ç–∞—Ç bin_packing: {len(placed_layouts)} —Ä–∞–∑–º–µ—â–µ–Ω–Ω—ã—Ö –ª–∏—Å—Ç–æ–≤, {len(unplaced_polygons)} –Ω–µ—Ä–∞–∑–º–µ—â–µ–Ω–Ω—ã—Ö –ø–æ–ª–∏–≥–æ–Ω–æ–≤"
            )

            # Finalize
            optimization_progress.progress(100)
            optimization_status.text("‚úÖ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")

            # Clear progress indicators after a moment
            import time

            time.sleep(1)
            optimization_progress.empty()
            optimization_status.empty()

        except ValueError as e:
            # Handle order constraint violations
            if "–ù–∞—Ä—É—à–µ–Ω–∏–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –∑–∞–∫–∞–∑–æ–≤" in str(e):
                st.error(f"‚ùå {str(e)}")
                st.info(
                    f"üí° **–†–µ—à–µ–Ω–∏–µ**: –£–≤–µ–ª–∏—á—å—Ç–µ –∫–æ–Ω—Å—Ç–∞–Ω—Ç—É MAX_SHEETS_PER_ORDER (—Å–µ–π—á–∞—Å: {MAX_SHEETS_PER_ORDER}) –∏–ª–∏ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ —Ñ–∞–π–ª—ã –∑–∞–∫–∞–∑–∞ –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ —á–∞—Å—Ç–µ–π."
                )
                st.stop()
            else:
                # Re-raise other ValueError exceptions
                raise

        # Convert to old format for compatibility with existing display code
        st.info("üî® –°–æ–∑–¥–∞–Ω–∏–µ –≤—ã—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π...")
        results_progress = st.progress(0)
        results_status = st.empty()

        all_layouts = []
        report_data = []

        total_layouts = len(placed_layouts)
        for i, layout in enumerate(placed_layouts):
            # Update progress
            progress_value = (
                int((i / total_layouts) * 100) if total_layouts > 0 else 100
            )
            results_progress.progress(progress_value)
            results_status.text(
                f"–°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ {i + 1}/{total_layouts}: –ª–∏—Å—Ç {layout['sheet_number']}"
            )

            # Save and visualize layout with new naming format: length_width_number_color.dxf
            sheet_width = int(layout["sheet_size"][0])
            sheet_height = int(layout["sheet_size"][1])
            sheet_number = layout["sheet_number"]

            # Find sheet color from original sheet data
            sheet_color = "–Ω–µ —É–∫–∞–∑–∞–Ω"
            color_suffix = "unknown"

            # Try to get sheet color from layout first, then match by name
            if "sheet_color" in layout:
                sheet_color = layout["sheet_color"]
            elif "sheet_type" in layout:
                for sheet in st.session_state.available_sheets:
                    if sheet["name"] == layout["sheet_type"]:
                        sheet_color = sheet.get("color", "–Ω–µ —É–∫–∞–∑–∞–Ω")
                        break
            else:
                # Fallback: use first available sheet color
                if st.session_state.available_sheets:
                    sheet_color = st.session_state.available_sheets[0].get(
                        "color", "–Ω–µ —É–∫–∞–∑–∞–Ω"
                    )

            # Convert color name to English suffix
            if sheet_color == "—á—ë—Ä–Ω—ã–π":
                color_suffix = "black"
            elif sheet_color == "—Å–µ—Ä—ã–π":
                color_suffix = "gray"
            else:
                color_suffix = "unknown"

            output_filename = (
                f"{sheet_height}_{sheet_width}_{sheet_number}_{color_suffix}.dxf"
            )
            output_file = os.path.join(OUTPUT_FOLDER, output_filename)

            save_dxf_layout_complete(
                layout["placed_polygons"],
                layout["sheet_size"],
                output_file,
                original_dxf_data_map,
            )
            layout_plot = plot_layout(layout["placed_polygons"], layout["sheet_size"])

            # Store layout info in old format for compatibility
            shapes_count = len(layout["placed_polygons"])
            logger.info(
                f"–õ–∏—Å—Ç #{layout['sheet_number']}: —Å–æ–∑–¥–∞–µ–º all_layouts –∑–∞–ø–∏—Å—å —Å {shapes_count} —Ä–∞–∑–º–µ—â–µ–Ω–Ω—ã–º–∏ –ø–æ–ª–∏–≥–æ–Ω–∞–º–∏"
            )

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –ª–∏—Å—Ç–∞ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –Ω–∞–ª–∏—á–∏—è –∫–ª—é—á–∞
            if "sheet_type" in layout:
                sheet_type = layout["sheet_type"]
            elif "sheet_color" in layout:
                sheet_type = layout["sheet_color"]
            else:
                # Fallback: –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã–π –¥–æ—Å—Ç—É–ø–Ω—ã–π –ª–∏—Å—Ç –∫–∞–∫ —Ç–∏–ø
                if st.session_state.available_sheets:
                    sheet_type = st.session_state.available_sheets[0].get(
                        "name", "Unknown"
                    )
                else:
                    sheet_type = "Unknown"

            all_layouts.append(
                {
                    "Sheet": layout["sheet_number"],
                    "Sheet Type": sheet_type,
                    "Sheet Color": sheet_color,
                    "Sheet Size": f"{layout['sheet_size'][0]}x{layout['sheet_size'][1]} —Å–º",
                    "Output File": output_file,
                    "Plot": layout_plot,
                    "Shapes Placed": shapes_count,
                    "Material Usage (%)": f"{layout['usage_percent']:.2f}",
                    "Placed Polygons": layout["placed_polygons"],
                }
            )
            report_data.extend(
                [
                    (p[4], layout["sheet_number"], output_file)
                    for p in layout["placed_polygons"]
                ]
            )

        # Finalize results processing
        results_progress.progress(100)
        results_status.text("‚úÖ –í—Å–µ —Ñ–∞–π–ª—ã —Å–æ–∑–¥–∞–Ω—ã.")

        # Update sheet inventory in session state
        for layout in placed_layouts:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –ª–∏—Å—Ç–∞ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –Ω–∞–ª–∏—á–∏—è –∫–ª—é—á–∞
            layout_sheet_type = None
            if "sheet_type" in layout:
                layout_sheet_type = layout["sheet_type"]
            elif "sheet_color" in layout:
                # –ï—Å–ª–∏ –Ω–µ—Ç sheet_type, –ø–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ª–∏—Å—Ç –ø–æ —Ü–≤–µ—Ç—É –∏ —Ä–∞–∑–º–µ—Ä—É
                sheet_color = layout["sheet_color"]
                sheet_size = layout.get("sheet_size", (0, 0))
                for sheet in st.session_state.available_sheets:
                    if (
                        sheet.get("color", "") == sheet_color
                        and sheet.get("width", 0) == sheet_size[0]
                        and sheet.get("height", 0) == sheet_size[1]
                    ):
                        layout_sheet_type = sheet["name"]
                        break

            if layout_sheet_type:
                for original_sheet in st.session_state.available_sheets:
                    if layout_sheet_type == original_sheet["name"]:
                        original_sheet["used"] += 1
                        break

        # Clear progress indicators
        import time

        time.sleep(1)
        results_progress.empty()
        results_status.empty()

        # Save results to session state to prevent loss on rerun
        st.session_state.optimization_results = {
            "all_layouts": all_layouts,
            "report_data": report_data,
            "unplaced_polygons": unplaced_polygons,
            "polygons_count": len(carpets),
            "placed_layouts": placed_layouts,  # Raw results from bin_packing
            "original_dxf_data_map": original_dxf_data_map,
            "original_dimensions": original_dimensions,
        }

# Display Results (moved outside the optimization block)
if "optimization_results" in st.session_state and st.session_state.optimization_results:
    # Add button to clear results
    if st.button(
        "üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã",
        help="–û—á–∏—Å—Ç–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è –Ω–æ–≤–æ–≥–æ —Ä–∞—Å—á–µ—Ç–∞",
    ):
        st.session_state.optimization_results = None
        st.rerun()

if "optimization_results" in st.session_state and st.session_state.optimization_results:
    results = st.session_state.optimization_results
    all_layouts = results["all_layouts"]
    report_data = results["report_data"]
    unplaced_polygons = results["unplaced_polygons"]
    polygons_count = results["polygons_count"]
    placed_layouts = results["placed_layouts"]
    original_dxf_data_map = results["original_dxf_data_map"]
    original_dimensions = results.get("original_dimensions", {})

    st.header("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã")
    if all_layouts:
        st.success(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –ª–∏—Å—Ç–æ–≤: {len(all_layouts)}")

        # Summary statistics
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("–í—Å–µ–≥–æ –ª–∏—Å—Ç–æ–≤", len(all_layouts))
        with col2:
            # Calculate correctly: actual placed polygons from bin_packing result
            # Should equal total_input_polygons - len(unplaced_polygons)
            total_input_polygons = polygons_count
            actual_placed_count = total_input_polygons - len(unplaced_polygons)

            # Debug: log the calculation
            raw_count_from_layouts = sum(
                len(layout["placed_polygons"]) for layout in placed_layouts
            )
            logger.info(
                f"DEBUG –ø–æ–¥—Å—á–µ—Ç: raw_from_layouts={raw_count_from_layouts}, calculated_placed={actual_placed_count}, input={total_input_polygons}, unplaced={len(unplaced_polygons)}"
            )

            logger.info(
                f"UI –ø–æ–¥—Å—á–µ—Ç: actual_placed={actual_placed_count}, total_input={total_input_polygons}, unplaced={len(unplaced_polygons)}"
            )
            logger.info(
                f"–ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ –ø–æ –ª–∏—Å—Ç–∞–º: {[(layout['sheet_number'], len(layout['placed_polygons'])) for layout in placed_layouts]}"
            )
            st.metric(
                "–†–∞–∑–º–µ—â–µ–Ω–æ –æ–±—ä–µ–∫—Ç–æ–≤", f"{actual_placed_count}/{total_input_polygons}"
            )
        with col3:
            avg_usage = sum(
                float(layout["Material Usage (%)"].replace("%", ""))
                for layout in all_layouts
            ) / len(all_layouts)
            st.metric("–°—Ä–µ–¥–Ω–∏–π —Ä–∞—Å—Ö–æ–¥ –º–∞—Ç–µ—Ä–∏–∞–ª–∞", f"{avg_usage:.1f}%")
        with col4:
            if unplaced_polygons:
                st.metric(
                    "–ù–µ —Ä–∞–∑–º–µ—â–µ–Ω–æ",
                    len(unplaced_polygons),
                    delta=f"-{len(unplaced_polygons)}",
                    delta_color="inverse",
                )
            else:
                st.metric("–ù–µ —Ä–∞–∑–º–µ—â–µ–Ω–æ", 0, delta="–í—Å–µ —Ä–∞–∑–º–µ—â–µ–Ω–æ ‚úÖ")

        # Show updated inventory
        st.subheader("üì¶ –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –∏–Ω–≤–µ–Ω—Ç–∞—Ä—å –ª–∏—Å—Ç–æ–≤")
        updated_sheets_data = []
        for sheet in st.session_state.available_sheets:
            # Add color indicator
            color = sheet.get("color", "–Ω–µ —É–∫–∞–∑–∞–Ω")
            color_emoji = (
                "‚ö´" if color == "—á—ë—Ä–Ω—ã–π" else "‚ö™" if color == "—Å–µ—Ä—ã–π" else "üîò"
            )
            color_display = f"{color_emoji} {color}"

            updated_sheets_data.append(
                {
                    "–¢–∏–ø –ª–∏—Å—Ç–∞": sheet["name"],
                    "–†–∞–∑–º–µ—Ä (—Å–º)": f"{sheet['width']}x{sheet['height']}",
                    "–¶–≤–µ—Ç": color_display,
                    "–ë—ã–ª–æ": sheet["count"],
                    "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ": sheet["used"],
                    "–û—Å—Ç–∞–ª–æ—Å—å": sheet["count"] - sheet["used"],
                }
            )
        updated_df = pd.DataFrame(updated_sheets_data)
        st.dataframe(updated_df, use_container_width=True)

        # Detailed results table with sizes
        st.subheader("üìã –ü–æ–¥—Ä–æ–±–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")

        # Create enhanced report with sizes
        enhanced_report_data = []
        for layout in all_layouts:
            for placed_tuple in layout["Placed Polygons"]:
                if len(placed_tuple) >= 6:  # New format with color
                    polygon, _, _, angle, file_name, color = placed_tuple[:6]
                else:  # Old format without color
                    polygon, _, _, angle, file_name = placed_tuple[:5]
                    color = "—Å–µ—Ä—ã–π"
                bounds = polygon.bounds
                width_cm = (bounds[2] - bounds[0]) / 10
                height_cm = (bounds[3] - bounds[1]) / 10
                area_cm2 = polygon.area / 100

                # Compare with original dimensions
                original = original_dimensions.get(file_name, {})
                original_width = original.get("width_cm", 0)
                original_height = original.get("height_cm", 0)
                original_area = original.get("area_cm2", 0)

                scale_factor = (
                    (width_cm / original_width) if original_width > 0 else 1.0
                )

                size_comparison = f"{width_cm:.1f}√ó{height_cm:.1f}"
                if abs(scale_factor - 1.0) > 0.01:  # If scaled
                    size_comparison += (
                        f" (–±—ã–ª–æ {original_width:.1f}√ó{original_height:.1f})"
                    )

                enhanced_report_data.append(
                    {
                        "DXF —Ñ–∞–π–ª": file_name,
                        "–ù–æ–º–µ—Ä –ª–∏—Å—Ç–∞": layout["Sheet"],
                        # "–†–∞–∑–º–µ—Ä (—Å–º)": size_comparison,
                        # "–ü–ª–æ—â–∞–¥—å (—Å–º¬≤)": f"{area_cm2:.2f}",
                        "–ü–æ–≤–æ—Ä–æ—Ç (¬∞)": f"{angle:.0f}",
                        "–í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª": layout["Output File"],
                    }
                )

        if enhanced_report_data:
            enhanced_df = pd.DataFrame(enhanced_report_data)
            st.dataframe(enhanced_df, use_container_width=True)
            # Also create simple report_df for export
            report_df = pd.DataFrame(
                report_data, columns=["DXF —Ñ–∞–π–ª", "–ù–æ–º–µ—Ä –ª–∏—Å—Ç–∞", "–í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª"]
            )
        else:
            report_df = pd.DataFrame(
                report_data, columns=["DXF —Ñ–∞–π–ª", "–ù–æ–º–µ—Ä –ª–∏—Å—Ç–∞", "–í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª"]
            )
            st.dataframe(report_df, use_container_width=True)

        # Sheet visualizations
        st.subheader("üìê –°—Ö–µ–º—ã —Ä–∞—Å–∫—Ä–æ—è –ª–∏—Å—Ç–æ–≤")
        for layout in all_layouts:
            # Add color indicator emoji
            color_emoji = (
                "‚ö´"
                if layout["Sheet Color"] == "—á—ë—Ä–Ω—ã–π"
                else "‚ö™"
                if layout["Sheet Color"] == "—Å–µ—Ä—ã–π"
                else "üîò"
            )

            st.write(
                f"**–õ–∏—Å—Ç ‚Ññ{layout['Sheet']}: {color_emoji} {layout['Sheet Type']} ({layout['Sheet Size']}) - {layout['Shapes Placed']} –æ–±—ä–µ–∫—Ç–æ–≤ - {layout['Material Usage (%)']}% —Ä–∞—Å—Ö–æ–¥**"
            )
            col1, col2 = st.columns([2, 1])
            with col1:
                st.image(
                    layout["Plot"],
                    caption=f"–†–∞—Å–∫—Ä–æ–π –ª–∏—Å—Ç–∞ ‚Ññ{layout['Sheet']} ({layout['Sheet Type']})",
                    use_container_width=True,
                )
            with col2:
                st.write(f"**–¢–∏–ø –ª–∏—Å—Ç–∞:** {layout['Sheet Type']}")
                st.write(f"**–¶–≤–µ—Ç –ª–∏—Å—Ç–∞:** {color_emoji} {layout['Sheet Color']}")
                st.write(f"**–†–∞–∑–º–µ—Ä –ª–∏—Å—Ç–∞:** {layout['Sheet Size']}")
                st.write(f"**–†–∞–∑–º–µ—â–µ–Ω–æ –æ–±—ä–µ–∫—Ç–æ–≤:** {layout['Shapes Placed']}")
                st.write(f"**–†–∞—Å—Ö–æ–¥ –º–∞—Ç–µ—Ä–∏–∞–ª–∞:** {layout['Material Usage (%)']}%")
                with open(layout["Output File"], "rb") as f:
                    st.download_button(
                        label="üì• –°–∫–∞—á–∞—Ç—å DXF",
                        data=f,
                        file_name=os.path.basename(layout["Output File"]),
                        mime="application/dxf",
                        key=f"download_{layout['Sheet']}",
                    )
            st.divider()  # Add visual separator between sheets
    else:
        st.error(
            "‚ùå –ù–µ –±—ã–ª–æ —Å–æ–∑–¥–∞–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ –ª–∏—Å—Ç–∞. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –æ—Ç–ª–∞–¥–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤—ã—à–µ."
        )

    # Show unplaced polygons if any
    if unplaced_polygons:
        st.warning(f"‚ö†Ô∏è {len(unplaced_polygons)} –æ–±—ä–µ–∫—Ç–æ–≤ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞–∑–º–µ—Å—Ç–∏—Ç—å.")
        st.subheader("üö´ –ù–µ—Ä–∞–∑–º–µ—â–µ–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã")
        unplaced_data = []
        for carpet in unplaced_polygons:
            unplaced_data.append(
                (carpet.filename, f"{carpet.polygon.area/100:.2f}", carpet.color)
            )

        unplaced_df = pd.DataFrame(
            unplaced_data, columns=["–§–∞–π–ª", "–ü–ª–æ—â–∞–¥—å (—Å–º¬≤)", "–¶–≤–µ—Ç"]
        )
        st.dataframe(unplaced_df, use_container_width=True)

    # Save report
    if all_layouts:
        report_file = os.path.join(
            OUTPUT_FOLDER,
            f"layout_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
        )

        # Use enhanced report if available, otherwise simple report
        if enhanced_report_data:
            enhanced_df.to_excel(report_file, index=False)
        elif "report_df" in locals():
            report_df.to_excel(report_file, index=False)
        else:
            # Fallback: create simple report from report_data
            fallback_df = pd.DataFrame(
                report_data, columns=["DXF —Ñ–∞–π–ª", "–ù–æ–º–µ—Ä –ª–∏—Å—Ç–∞", "–í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª"]
            )
            fallback_df.to_excel(report_file, index=False)

        # Create ZIP archive with all DXF files
        zip_filename = f"layout_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip"
        zip_path = os.path.join(OUTPUT_FOLDER, zip_filename)

        with zipfile.ZipFile(zip_path, "w", zipfile.ZIP_DEFLATED) as zipf:
            # Add all DXF layout files
            for layout in all_layouts:
                dxf_file_path = layout["Output File"]
                if os.path.exists(dxf_file_path):
                    # Use the new naming format for files in zip
                    arcname = os.path.basename(dxf_file_path)
                    zipf.write(dxf_file_path, arcname)

            # Add report file
            if os.path.exists(report_file):
                zipf.write(report_file, os.path.basename(report_file))

        # Download buttons
        col1, col2 = st.columns([1, 1])

        with col1:
            with open(report_file, "rb") as f:
                st.download_button(
                    label="üìä –°–∫–∞—á–∞—Ç—å –æ—Ç—á–µ—Ç Excel",
                    data=f,
                    file_name=os.path.basename(report_file),
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                )

        with col2:
            with open(zip_path, "rb") as f:
                st.download_button(
                    label="üì¶ –°–∫–∞—á–∞—Ç—å –≤—Å–µ —Ñ–∞–π–ª—ã (ZIP)",
                    data=f,
                    file_name=zip_filename,
                    mime="application/zip",
                )
